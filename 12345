import pandas as pd
import numpy as np
import xgboost as xgb
import shap
import optuna
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OrdinalEncoder

# =============== 1. 参数设置 ==================
target_col = 'target'
categorical_cols = [...]  # 比如 ['state', 'claim_type']
feature_cols = [...]      # 所有用于建模的特征列（包括分类变量）

# =============== 2. 编码器定义（方便复用） ==================
encoder = OrdinalEncoder()

def encode_data(df, fit=False):
    df_copy = df.copy()
    if fit:
        df_copy[categorical_cols] = encoder.fit_transform(df_copy[categorical_cols])
    else:
        df_copy[categorical_cols] = encoder.transform(df_copy[categorical_cols])
    return df_copy








    















# =============== 3. 训练数据编码 ==================
df_encoded = encode_data(df, fit=True)

X = df_encoded[feature_cols]
y = df_encoded[target_col]
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)

# =============== 4. Optuna 调参 ==================
def objective(trial):
    params = {
        'objective': 'reg:squarederror',
        'eval_metric': 'rmse',
        'tree_method': 'hist',
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
        'max_depth': trial.suggest_int('max_depth', 3, 10),
        'min_child_weight': trial.suggest_float('min_child_weight', 1e-3, 10.0),
        'subsample': trial.suggest_float('subsample', 0.5, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),
        'lambda': trial.suggest_float('lambda', 1e-3, 10.0),
        'alpha': trial.suggest_float('alpha', 1e-3, 10.0),
    }

    dtrain = xgb.DMatrix(X_train, label=y_train)
    dvalid = xgb.DMatrix(X_valid, label=y_valid)
    booster = xgb.train(params, dtrain, 1000, [(dvalid, 'valid')],
                        early_stopping_rounds=50, verbose_eval=False)

    preds = booster.predict(dvalid)
    return mean_squared_error(y_valid, preds, squared=False)

study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=50)

# =============== 5. 训练最终模型 ==================
best_params = study.best_trial.params
best_params.update({
    'objective': 'reg:squarederror',
    'eval_metric': 'rmse',
    'tree_method': 'hist'
})

dtrain_full = xgb.DMatrix(X, label=y)
final_model = xgb.train(best_params, dtrain_full, num_boost_round=study.best_trial.number)







explainer = shap.Explainer(final_model, X)
shap_values = explainer(X)

shap.summary_plot(shap_values, X)
















# =============== 6. OOT 数据处理 ==================
df_oot_encoded = encode_data(df_oot, fit=False)
X_oot = df_oot_encoded[feature_cols]

# 预测
df_oot_encoded['predicted'] = final_model.predict(xgb.DMatrix(X_oot))

# =============== 7. OOT SHAP 分析 ==================
explainer_oot = shap.Explainer(final_model, X_oot)
shap_values_oot = explainer_oot(X_oot)

shap.summary_plot(shap_values_oot, X_oot)

# 可选导出
# df_oot_encoded.to_csv("oot_with_predictions.csv", index=False)
